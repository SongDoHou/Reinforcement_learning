{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 07. MonteCarlo-TreeSearch GYM-\n",
    "---\n",
    "- 목표: MCTS를 이용해 'MountainCar' 문제를 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.23.0 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (0.23.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (from gym==0.23.0) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (from gym==0.23.0) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (from gym==0.23.0) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (from gym==0.23.0) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.10.0->gym==0.23.0) (3.7.0)\n",
      "Requirement already satisfied: pyglet==2.0.0 in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: PyOpenGL in /home/hyunseok.hwang/anaconda3/lib/python3.9/site-packages (3.1.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install gym==0.23.0\n",
    "#!pip install pyglet==2.0.0\n",
    "#!pip install PyOpenGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "from gym.core import Wrapper\n",
    "from pickle import dumps, loads\n",
    "from collections import namedtuple\n",
    "from IPython.display import clear_output\n",
    "from itertools import count\n",
    "from tqdm import trange\n",
    "import copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.core import Wrapper\n",
    "from pickle import dumps, loads\n",
    "from collections import namedtuple\n",
    "\n",
    "# a container for get_result function below. Works just like tuple, but prettier\n",
    "ActionResult = namedtuple(\n",
    "    \"action_result\", (\"snapshot\", \"observation\", \"reward\", \"is_done\", \"info\"))\n",
    "\n",
    "\n",
    "class WithSnapshots(Wrapper):\n",
    "    \"\"\"\n",
    "    Creates a wrapper that supports saving and loading environemnt states.\n",
    "    Required for planning algorithms.\n",
    "\n",
    "    This class will have access to the core environment as self.env, e.g.:\n",
    "    - self.env.reset()           #reset original env\n",
    "    - self.env.ale.cloneState()  #make snapshot for atari. load with .restoreState()\n",
    "    - ...\n",
    "\n",
    "    You can also use reset() and step() directly for convenience.\n",
    "    - s = self.reset()                   # same as self.env.reset()\n",
    "    - s, r, done, _ = self.step(action)  # same as self.env.step(action)\n",
    "    \n",
    "    Note that while you may use self.render(), it will spawn a window that cannot be pickled.\n",
    "    Thus, you will need to call self.close() before pickling will work again.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_snapshot(self, render=False):\n",
    "        \"\"\"\n",
    "        :returns: environment state that can be loaded with load_snapshot \n",
    "        Snapshots guarantee same env behaviour each time they are loaded.\n",
    "\n",
    "        Warning! Snapshots can be arbitrary things (strings, integers, json, tuples)\n",
    "        Don't count on them being pickle strings when implementing MCTS.\n",
    "\n",
    "        Developer Note: Make sure the object you return will not be affected by \n",
    "        anything that happens to the environment after it's saved.\n",
    "        You shouldn't, for example, return self.env. \n",
    "        In case of doubt, use pickle.dumps or deepcopy.\n",
    "\n",
    "        \"\"\"\n",
    "        if render:\n",
    "            self.render()  # close popup windows since we can't pickle them\n",
    "            self.close()\n",
    "            \n",
    "        #if self.unwrapped.viewer is not None:\n",
    "        #    self.unwrapped.viewer.close()\n",
    "        #    self.unwrapped.viewer = None\n",
    "        return dumps(self.env)\n",
    "\n",
    "    def load_snapshot(self, snapshot, render=False):\n",
    "        \"\"\"\n",
    "        Loads snapshot as current env state.\n",
    "        Should not change snapshot inplace (in case of doubt, deepcopy).\n",
    "        \"\"\"\n",
    "\n",
    "        assert not hasattr(self, \"_monitor\") or hasattr(\n",
    "            self.env, \"_monitor\"), \"can't backtrack while recording\"\n",
    "\n",
    "        if render:\n",
    "            self.render()  # close popup windows since we can't load into them\n",
    "            self.close()\n",
    "        self.env = loads(snapshot)\n",
    "\n",
    "    def get_result(self, snapshot, action):\n",
    "        \"\"\"\n",
    "        A convenience function that \n",
    "        - loads snapshot, \n",
    "        - commits action via self.step,\n",
    "        - and takes snapshot again :)\n",
    "\n",
    "        :returns: next snapshot, next_observation, reward, is_done, info\n",
    "\n",
    "        Basically it returns next snapshot and everything that env.step would have returned.\n",
    "        \"\"\"\n",
    "\n",
    "        #<YOUR CODE: load, commit, take snapshot>\n",
    "        self.load_snapshot(snapshot)\n",
    "        new_state, reward, done, info = self.env.step(action)\n",
    "        next_snapshot = self.get_snapshot()\n",
    "        return ActionResult(\n",
    "            next_snapshot, \n",
    "            new_state, \n",
    "            reward, \n",
    "            done, \n",
    "            info,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_state:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make env\n",
    "#env = WithSnapshots(gym.make(\"MountainCar-v0\",render_mode='rgb_array'))\n",
    "env_name = \"MountainCar-v0\"\n",
    "env_name = 'CartPole-v0'\n",
    "env = WithSnapshots(gym.make(env_name))\n",
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "print(\"initial_state:\")\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "env.close()\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)\n",
    "#env = WithSnapshots(gym.make(\"MountainCar-v0\"))\n",
    "env = WithSnapshots(env)\n",
    "env.reset()\n",
    "\n",
    "snap0 = env.get_snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Tree Search \n",
    "---\n",
    "- Node 단계 클래스 구성\n",
    "\n",
    "- Root 단계 클래스 구성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"A tree node for MCTS.\n",
    "    \n",
    "    Each Node corresponds to the result of performing a particular action (self.action)\n",
    "    in a particular state (self.parent), and is essentially one arm in the multi-armed bandit that\n",
    "    we model in that state.\"\"\"\n",
    "    parent = None  # parent Node\n",
    "    qvalue_sum = 0.  # sum of Q-values from all visits (numerator)\n",
    "    times_visited = 0  # counter of visits (denominator)\n",
    "    \n",
    "    def __init__(self, parent, action):\n",
    "        \"\"\"\n",
    "        Creates and empty node with no children.\n",
    "        Does so by commiting an action and recording outcome.\n",
    "\n",
    "        :param parent: parent Node\n",
    "        :param action: action to commit from parent Node\n",
    "        \"\"\"\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.children = set()\n",
    "\n",
    "        res = env.get_result(parent.snapshot, action)\n",
    "        self.snapshot, self.observation, self.immediate_reward, self.is_done, _ = res\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def is_root(self):\n",
    "        return self.parent is None\n",
    "\n",
    "    def get_qvalue_estimate(self):\n",
    "        return self.qvalue_sum / self.times_visited if self.times_visited != 0 else 0\n",
    "\n",
    "    def ucb_score(self, scale=10, max_value=1e100):\n",
    "        if self.times_visited == 0:\n",
    "            return max_value\n",
    "\n",
    "        U = np.sqrt(2*np.log(self.parent.times_visited)/self.times_visited)\n",
    "        return self.get_qvalue_estimate() + scale * U\n",
    "\n",
    "    def select_best_leaf(self):\n",
    "        if self.is_leaf():\n",
    "            return self\n",
    "\n",
    "        children = self.children\n",
    "        best_child = max([(child.ucb_score(),child) for child in children], key=lambda x: x[0])[1]\n",
    "        return best_child.select_best_leaf()\n",
    "\n",
    "    def expand(self):\n",
    "        assert not self.is_done, \"can't expand from terminal state\"\n",
    "\n",
    "        for action in range(n_actions):\n",
    "            self.children.add(Node(self, action))\n",
    "        return self.select_best_leaf()\n",
    "\n",
    "    #def rollout(self, t_max=10**4):\n",
    "    def simulation(self, t_max=500):\n",
    "        \"\"\"\n",
    "        Play the game from this state to the end (done) or for t_max steps.\n",
    "\n",
    "        On each step, pick action at random (hint: env.action_space.sample()).\n",
    "\n",
    "        Compute sum of rewards from the current state until the end of the episode.\n",
    "        Note 1: use env.action_space.sample() for picking a random action.\n",
    "        Note 2: if the node is terminal (self.is_done is True), just return self.immediate_reward.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # set env into the appropriate state\n",
    "        env.load_snapshot(self.snapshot)\n",
    "        obs = self.observation\n",
    "        is_done = self.is_done\n",
    "\n",
    "        #<YOUR CODE: perform rollout and compute reward>\n",
    "        if is_done:\n",
    "            simulation_reward = 0\n",
    "        else:\n",
    "            simulation_reward = 0\n",
    "            while t_max > 0:\n",
    "                t_max -= 1\n",
    "                next_obs,reward,done,info=env.step(env.action_space.sample())\n",
    "                simulation_reward += reward\n",
    "        return simulation_reward\n",
    "\n",
    "    def propagate(self, child_qvalue, gamma=0.99):\n",
    "        my_qvalue = self.immediate_reward + gamma*child_qvalue\n",
    "\n",
    "        self.qvalue_sum += my_qvalue\n",
    "        self.times_visited += 1\n",
    "\n",
    "        # propagate upwards\n",
    "        if not self.is_root():\n",
    "            self.parent.propagate(my_qvalue)\n",
    "\n",
    "    def safe_delete(self):\n",
    "        \"\"\"safe delete to prevent memory leak in some python versions\"\"\"\n",
    "        del self.parent\n",
    "        for child in self.children:\n",
    "            child.safe_delete()\n",
    "            del child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Root(Node):\n",
    "    def __init__(self, snapshot, observation):\n",
    "        \"\"\"\n",
    "        creates special node that acts like tree root\n",
    "        :snapshot: snapshot (from env.get_snapshot) to start planning from\n",
    "        :observation: last environment observation\n",
    "        \"\"\"\n",
    "        self.parent = self.action = None\n",
    "        self.children = set()  # set of child nodes\n",
    "\n",
    "        self.snapshot = snapshot\n",
    "        self.observation = observation\n",
    "        self.immediate_reward = 0\n",
    "        self.is_done = False\n",
    "\n",
    "    @staticmethod\n",
    "    def from_node(node):\n",
    "        \"\"\"initializes node as root\"\"\"\n",
    "        root = Root(node.snapshot, node.observation)\n",
    "        # copy data\n",
    "        copied_fields = [\"qvalue_sum\", \"times_visited\", \"children\", \"is_done\"]\n",
    "        for field in copied_fields:\n",
    "            setattr(root, field, getattr(node, field))\n",
    "        return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo TreeSearch 반복회차\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_mcts(root, n_iters=10):\n",
    "    \"\"\"\n",
    "    builds tree with monte-carlo tree search for n_iters iterations\n",
    "    :param root: tree node to plan from\n",
    "    :param n_iters: how many select-expand-simulate-propagete loops to make\n",
    "    \"\"\"\n",
    "    #for _ in range(n_iters):\n",
    "    for _ in trange(n_iters):\n",
    "        #<YOUR CODE: select best leaf>\n",
    "        node = root.select_best_leaf()\n",
    "\n",
    "        if node.is_done:\n",
    "            # All rollouts from a terminal node are empty, and thus have 0 reward.\n",
    "            node.propagate(0)\n",
    "        else:\n",
    "            # Expand the best leaf. Perform a rollout from it. Propagate the results upwards.\n",
    "            # Note that here you have some leeway in choosing where to propagate from.\n",
    "            # Any reasonable choice should work.\n",
    "            \n",
    "            #<YOUR CODE>\n",
    "            node_child = node.expand()\n",
    "            child_reward = node_child.simulation()\n",
    "            node.propagate(child_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name)\n",
    "#env.max_episode_steps=500\n",
    "env = WithSnapshots(env)\n",
    "\n",
    "#env = WithSnapshots(gym.make(\"MountainCar-v0\"))\n",
    "#env.max_episode_steps = 500\n",
    "\n",
    "root_observation = env.reset()\n",
    "root_snapshot = env.get_snapshot()\n",
    "root = Root(root_snapshot, root_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:25<00:00, 117.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# plan from root: \n",
    "plan_mcts(root, n_iters=10**4)\n",
    "root_backup = copy.deepcopy(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with reward =  200.0\n"
     ]
    }
   ],
   "source": [
    "total_reward = 0  # sum of rewards\n",
    "test_env = loads(root_snapshot)  # env used to show progress\n",
    "\n",
    "for i in count():\n",
    "    # get best child\n",
    "    #<YOUR CODE: select child with the highest mean reward>\n",
    "    best_child = max([(child.get_qvalue_estimate(),child) for child in root.children], key=lambda x: x[0])[1]\n",
    "\n",
    "    # take action\n",
    "    s, r, done, _ = test_env.step(best_child.action)\n",
    "\n",
    "    # show image\n",
    "    clear_output(True)\n",
    "    plt.title(\"step %i\" % i)\n",
    "    plt.imshow(test_env.render('rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "    total_reward += r\n",
    "    if done:\n",
    "        print(\"Finished with reward = \", total_reward)\n",
    "        break\n",
    "\n",
    "    # discard unrealized part of the tree [because not every child matters :(]\n",
    "    for child in root.children:\n",
    "        if child != best_child:\n",
    "            child.safe_delete()\n",
    "\n",
    "    # declare best child a new root\n",
    "    root = Root.from_node(best_child)\n",
    "\n",
    "    assert not root.is_leaf(), \\\n",
    "        \"We ran out of tree! Need more planning! Try growing the tree right inside the loop.\"\n",
    "\n",
    "    # You may want to run more planning here\n",
    "    # <YOUR CODE>\n",
    "    #if root.is_leaf():\n",
    "    #    plan_mcts(root,n_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_Scratch",
   "language": "python",
   "name": "rl_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda1c160e83cbc6e162d86f3ac820d0e78df5de1466a2ca6fc33fee2ec17e6f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
